{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:41:36.408017Z",
     "start_time": "2023-03-29T12:41:35.786139Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsLO9QDMUoTo",
    "outputId": "969cc6f4-1d9a-4ffc-ff74-c07a27c65883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD Radeon RX 6900 XT\u0000\n",
      "Last updated: 2023-03-29T14:14:28.278123+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.13\n",
      "IPython version      : 8.6.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.10.16.3-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 32\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not (os.path.exists('./NaturalImageNetTest/') and os.path.exists('./NaturalImageNetTrain/')):\n",
    "    # !wget https://zenodo.org/record/5846979/files/NaturalImageNetTest.zip?download=1\n",
    "    # !wget https://zenodo.org/record/5846979/files/NaturalImageNetTrain.zip?download=1\n",
    "    !unzip -q NaturalImageNetTest.zip?download=1\n",
    "    !unzip -q NaturalImageNetTrain.zip?download=1\n",
    "\n",
    "#torch\n",
    "import time\n",
    "import torch\n",
    "from torch.nn import Conv2d, MaxPool2d, AvgPool2d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# set the seed for reproducibility\n",
    "rng_seed = 90\n",
    "torch.manual_seed(rng_seed)\n",
    "\n",
    "import torch_directml  # directml plugin\n",
    "device = torch_directml.device(0)  # 0 for discrete, 1 for integrated\n",
    "print(torch_directml.device_name(0))\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:41:37.471820Z",
     "start_time": "2023-03-29T12:41:37.363439Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XuC3wCSUoTp",
    "outputId": "1d3c1fc3-03ad-42a3-c108-de12a6f993c7"
   },
   "outputs": [],
   "source": [
    "mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "std = torch.Tensor([0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean.tolist(), std.tolist()),\n",
    "        ]\n",
    "    )\n",
    "train_path = './NaturalImageNetTrain'\n",
    "test_path = './NaturalImageNetTest'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Create train val split\n",
    "n = len(train_dataset)\n",
    "n_val = int(n/10)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [n-n_val, n_val])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "loader_val = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:44:04.080756Z",
     "start_time": "2023-03-29T12:44:04.075725Z"
    },
    "code_folding": [],
    "id": "bknm_PrxuW5r"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module): \n",
    "    def __init__(self, inchannel, outchannel, stride=1): \n",
    "        super(ResidualBlock, self).__init__() \n",
    "        self.left = nn.Sequential(Conv2d(inchannel, outchannel, kernel_size=3, \n",
    "                                         stride=stride, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel), \n",
    "                                  nn.ReLU(inplace=True), \n",
    "                                  Conv2d(outchannel, outchannel, kernel_size=3, \n",
    "                                         stride=1, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel)) \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel: \n",
    "            self.shortcut = nn.Sequential(Conv2d(inchannel, outchannel, \n",
    "                                                 kernel_size=1, stride=stride, \n",
    "                                                 padding = 0, bias=False), \n",
    "                                          nn.BatchNorm2d(outchannel) ) \n",
    "            \n",
    "    def forward(self, x): \n",
    "        out = self.left(x) \n",
    "        out += self.shortcut(x) \n",
    "        out = F.relu(out) \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ResidualBlock, num_classes = 20):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 8\n",
    "        self.conv1 = nn.Sequential(Conv2d(3, 8, kernel_size = 3, stride = 1,\n",
    "                                            padding = 1, bias = False), \n",
    "                                  nn.BatchNorm2d(8), \n",
    "                                  nn.ReLU())\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 8, 2, stride = 2)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 16, 2, stride = 2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 32, 2, stride = 2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 64, 2, stride = 2)\n",
    "        self.layer5 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
    "        self.layer6 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
    "        self.maxpool = MaxPool2d(4)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def MyResNet():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:44:22.459910Z",
     "start_time": "2023-03-29T12:44:22.450745Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AynHSTv3uW55",
    "outputId": "f018a4a0-b5b5-4bd0-a3cb-9593750e0d60"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "print_every = 1\n",
    "\n",
    "def train_part(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)\n",
    "    for e in range(epochs):\n",
    "        start = time.time()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            print('\\nBefore loss.backward()')\n",
    "            for param in optimizer.param_groups[0]['params']:\n",
    "                # print(param)\n",
    "                print('Grad', param.grad)            \n",
    "\n",
    "            loss.backward()\n",
    "            print('\\nAfter loss.backward(), before optimiser.step()')\n",
    "            for param in optimizer.param_groups[0]['params']:\n",
    "#                 print(param)\n",
    "                print('Grad', param.grad)\n",
    "\n",
    "            optimizer.step()\n",
    "            print('\\nAfter optimiser.step()')\n",
    "            for param in optimizer.param_groups[0]['params']:\n",
    "                # print(param)\n",
    "                print('Grad', param.grad)\n",
    "\n",
    "            end = time.time()\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch: %d, Iteration %d, loss = %.4f, epoch time = %d s' %\n",
    "                      (e, t, loss.item(), end-start), end='\\r')\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T12:45:57.671760Z",
     "start_time": "2023-03-29T12:44:23.205946Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q_6N1VZQuW58",
    "outputId": "f6f297e1-c358-4908-b2ce-be50984945a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: privateuseone:0\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [128, 20]                 --\n",
      "├─Sequential: 1-1                        [128, 8, 256, 256]        --\n",
      "│    └─Conv2d: 2-1                       [128, 8, 256, 256]        216\n",
      "│    └─BatchNorm2d: 2-2                  [128, 8, 256, 256]        16\n",
      "│    └─ReLU: 2-3                         [128, 8, 256, 256]        --\n",
      "├─Sequential: 1-2                        [128, 8, 128, 128]        --\n",
      "│    └─ResidualBlock: 2-4                [128, 8, 128, 128]        --\n",
      "│    │    └─Sequential: 3-1              [128, 8, 128, 128]        1,184\n",
      "│    │    └─Sequential: 3-2              [128, 8, 128, 128]        80\n",
      "│    └─ResidualBlock: 2-5                [128, 8, 128, 128]        --\n",
      "│    │    └─Sequential: 3-3              [128, 8, 128, 128]        1,184\n",
      "│    │    └─Sequential: 3-4              [128, 8, 128, 128]        --\n",
      "├─Sequential: 1-3                        [128, 16, 64, 64]         --\n",
      "│    └─ResidualBlock: 2-6                [128, 16, 64, 64]         --\n",
      "│    │    └─Sequential: 3-5              [128, 16, 64, 64]         3,520\n",
      "│    │    └─Sequential: 3-6              [128, 16, 64, 64]         160\n",
      "│    └─ResidualBlock: 2-7                [128, 16, 64, 64]         --\n",
      "│    │    └─Sequential: 3-7              [128, 16, 64, 64]         4,672\n",
      "│    │    └─Sequential: 3-8              [128, 16, 64, 64]         --\n",
      "├─Sequential: 1-4                        [128, 32, 32, 32]         --\n",
      "│    └─ResidualBlock: 2-8                [128, 32, 32, 32]         --\n",
      "│    │    └─Sequential: 3-9              [128, 32, 32, 32]         13,952\n",
      "│    │    └─Sequential: 3-10             [128, 32, 32, 32]         576\n",
      "│    └─ResidualBlock: 2-9                [128, 32, 32, 32]         --\n",
      "│    │    └─Sequential: 3-11             [128, 32, 32, 32]         18,560\n",
      "│    │    └─Sequential: 3-12             [128, 32, 32, 32]         --\n",
      "├─Sequential: 1-5                        [128, 64, 16, 16]         --\n",
      "│    └─ResidualBlock: 2-10               [128, 64, 16, 16]         --\n",
      "│    │    └─Sequential: 3-13             [128, 64, 16, 16]         55,552\n",
      "│    │    └─Sequential: 3-14             [128, 64, 16, 16]         2,176\n",
      "│    └─ResidualBlock: 2-11               [128, 64, 16, 16]         --\n",
      "│    │    └─Sequential: 3-15             [128, 64, 16, 16]         73,984\n",
      "│    │    └─Sequential: 3-16             [128, 64, 16, 16]         --\n",
      "├─Sequential: 1-6                        [128, 128, 8, 8]          --\n",
      "│    └─ResidualBlock: 2-12               [128, 128, 8, 8]          --\n",
      "│    │    └─Sequential: 3-17             [128, 128, 8, 8]          221,696\n",
      "│    │    └─Sequential: 3-18             [128, 128, 8, 8]          8,448\n",
      "│    └─ResidualBlock: 2-13               [128, 128, 8, 8]          --\n",
      "│    │    └─Sequential: 3-19             [128, 128, 8, 8]          295,424\n",
      "│    │    └─Sequential: 3-20             [128, 128, 8, 8]          --\n",
      "├─Sequential: 1-7                        [128, 256, 4, 4]          --\n",
      "│    └─ResidualBlock: 2-14               [128, 256, 4, 4]          --\n",
      "│    │    └─Sequential: 3-21             [128, 256, 4, 4]          885,760\n",
      "│    │    └─Sequential: 3-22             [128, 256, 4, 4]          33,280\n",
      "│    └─ResidualBlock: 2-15               [128, 256, 4, 4]          --\n",
      "│    │    └─Sequential: 3-23             [128, 256, 4, 4]          1,180,672\n",
      "│    │    └─Sequential: 3-24             [128, 256, 4, 4]          --\n",
      "├─MaxPool2d: 1-8                         [128, 256, 1, 1]          --\n",
      "├─Linear: 1-9                            [128, 20]                 5,140\n",
      "==========================================================================================\n",
      "Total params: 2,806,252\n",
      "Trainable params: 2,806,252\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 28.25\n",
      "==========================================================================================\n",
      "Input size (MB): 100.66\n",
      "Forward/backward pass size (MB): 3716.17\n",
      "Params size (MB): 11.23\n",
      "Estimated Total Size (MB): 3828.06\n",
      "==========================================================================================\n",
      "Total number of parameters is: 2806252\n",
      "\n",
      "Before loss.backward()\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "\n",
      "After loss.backward(), before optimiser.step()\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "\n",
      "After optimiser.step()\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Grad None\n",
      "Epoch: 0, Iteration 0, loss = 4.1321, epoch time = 1 s\r"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/AI Programmes/torchdml_test/torchdml_test.ipynb Cell 7\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m params \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal number of parameters is: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(params))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m train_part(model, optimizer, epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/e/AI Programmes/torchdml_test/torchdml_test.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39m%\u001b[39m print_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, Iteration \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, loss = \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m, epoch time = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m s\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m           (e, t, loss\u001b[39m.\u001b[39mitem(), end\u001b[39m-\u001b[39mstart), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/e/AI%20Programmes/torchdml_test/torchdml_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define and train the network\n",
    "model = MyResNet()\n",
    "print('device:', device)\n",
    "print(summary(model, input_size=(batch_size, 3, 256, 256)))\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4, weight_decay=1e-7) \n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-7)\n",
    "\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters is: {}\".format(params))\n",
    "\n",
    "train_part(model, optimizer, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "460cw1_2022_sample_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "notify_time": "5",
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "BatchNorm Layer": {
     "name": "BatchNorm Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(BatchNorm2d(2)(torch.zeros((3,2,7,6))).shape) == [3,2,7,6]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(BatchNorm2d(2)(torch.zeros((3,2,7,6)))) == torch.Tensor\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(BatchNorm2d(2), 'gamma') and hasattr(BatchNorm2d(2), 'beta')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = BatchNorm2d(7)\n>>> (list(torch.squeeze(layer.gamma).shape) == [7])  and (list(torch.squeeze(layer.beta).shape) == [7])\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Convolution Layer": {
     "name": "Convolution Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = Conv2d(7,32,4)\n>>> (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Linear Layer": {
     "name": "Linear Layer",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(Linear(25,28)(torch.zeros((17,25))).shape) == [17,28]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(Linear(13,15)(torch.zeros((6,13)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        },
        {
         "code": ">>> hasattr(Linear(2,2), 'w') and hasattr(Linear(2,2), 'b')\nTrue",
         "failure_message": "Param Name Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Name Test Passed"
        },
        {
         "code": ">>> layer = Linear(13,24)\n>>> (list(layer.w.shape) in [[13,24], [24,13]])  and (list(layer.b.shape) == [24])\nTrue",
         "failure_message": "Param Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Param Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MaxPool Layer": {
     "name": "MaxPool Layer",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\nTrue",
         "failure_message": "Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Shape Test Passed"
        },
        {
         "code": ">>> type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\nTrue",
         "failure_message": "Type Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Type Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6371493ce6af2db66d56c27f5ffc1412103493d82a9060c4c40d6c28546ccfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
